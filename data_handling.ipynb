{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ABD final project: Data handling\n",
    "## Python version\n",
    "3.5 onwards\n",
    "\n",
    "## Modules needed\n",
    "* pandas\n",
    "* numpy\n",
    "* openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncoment to install modules inside the notebook\n",
    "# !pip install pandas\n",
    "# !pip install openpyxl\n",
    "\n",
    "import openpyxl\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from pandas import Series, DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DataFrame formatting\n",
    "\n",
    "## Nginx default log format\n",
    "```\n",
    "'$remote_addr - $remote_user [$time_local] \"$request\" '\n",
    "'$status $body_bytes_sent \"$http_referer\" '\n",
    "'\"$http_user_agent\" \"$http_x_forwarded_for\"'\n",
    "```                      \n",
    "\n",
    "## Formating DataFrames\n",
    "After loading the data and the output DataFrame\n",
    "\n",
    "### DataFrame after data load\n",
    "Reading with a space character as the separation:\n",
    "\n",
    "row | 0 | 1 | 2 | 3 | 4 | 5 | 6 | 7 | 8 | 9 | 10\n",
    "--- | --- | --- | --- | --- |--- |--- |--- |--- |--- |--- |---\n",
    "\\# | \\$remote_addr | - | \\$remote_user | [\\$time_local(time) | \\$time_local(locale)] | \\$request | \\$status | \\$body_bytes_sent | \\$http_referer | \\$http_user_agent | \\$http_x_forwarded_for\n",
    "\n",
    "### Output DataFrame\n",
    "After the formatting, ready to the human read and fill:\n",
    "\n",
    "row | http_user_agent | request_method | status | request_url | is_evil\n",
    "--- | --- | --- | --- | --- |--- \n",
    "\\# | String | GET or POST | int | String | Empty String\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the full log history in a DataFrame\n",
    "df_data = pd.read_csv('data/full_log.log', sep=\" \", header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Joining $time_local(time) and $time_local(locale) columns in a single 'time' column\n",
    "df_data['time'] = df_data[3] + ' ' + df_data[4]\n",
    "\n",
    "# Splitting $request column in three: 'method', 'url' and 'protocol' columns\n",
    "df_data['method'], df_data['url'], df_data['protocol'] = df_data[5].str.split(' ', 2).str\n",
    "\n",
    "# Dropping '-', $remote_user, $time_local(time), $time_local(locale), $request and $body_bytes_sent columns\n",
    "df_data.drop([1, 2, 3, 4, 5, 7], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rows before deleting: 7823\n",
      "rows deleted: 60\n",
      "final rows: 7763\n"
     ]
    }
   ],
   "source": [
    "# Showing DataFrame length\n",
    "print('rows before deleting:', len(df_data))\n",
    "\n",
    "# Declaring an auxiliar DataFrame to get the rows with at least 1 NaN value\n",
    "df_aux = df_data[df_data.isna().any(axis=1)]\n",
    "\n",
    "# Dropping the rows with null values\n",
    "df_data.dropna(inplace=True)\n",
    "\n",
    "# Showing deleted and final lengths\n",
    "print('rows deleted:', len(df_aux))\n",
    "print('final rows:', len(df_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "there was 110 http_referer notnull records\n"
     ]
    }
   ],
   "source": [
    "# Declaring an auxiliar DataFrame clonning the main DataFrame\n",
    "df_aux = df_data.copy()\n",
    "# Replace the '-' character with NaN in the $http_referer column in the auxiliar DataFrame\n",
    "df_aux[8].replace('-', pd.np.nan, inplace=True)\n",
    "# Getting all the rows with no NaN value in the $http_referer column in the auxiliar DataFrame\n",
    "df_aux = df_aux[~df_aux.isna().any(axis=1)]\n",
    "\n",
    "# Printing the auxiliar DataFrame length\n",
    "print('there was', len(df_aux), 'http_referer notnull records')\n",
    "\n",
    "# Dropping the $http_referer column\n",
    "df_data.drop([8], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "there was 13 http_x_forwarded_for notnull records\n"
     ]
    }
   ],
   "source": [
    "# Declaring an auxiliar DataFrame clonning the main DataFrame\n",
    "df_aux = df_data.copy()\n",
    "# Replace the '-' character with NaN in the $http_x_forwarded_for column in the auxiliar DataFrame\n",
    "df_aux[10].replace('-', pd.np.nan, inplace=True)\n",
    "# Getting all the rows with no NaN value in the $http_x_forwarded_for column in the auxiliar DataFrame\n",
    "df_aux = df_aux[~df_aux.isna().any(axis=1)]\n",
    "\n",
    "# Printing the auxiliar DataFrame length\n",
    "print('there was', len(df_aux), 'http_x_forwarded_for notnull records')\n",
    "\n",
    "# Dropping the $http_x_forwarded_for column\n",
    "df_data.drop([10], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "there was 46 non POST or GET records\n"
     ]
    }
   ],
   "source": [
    "# Declaring an auxiliar integer with the length of the DataFrame as value\n",
    "int_aux = len(df_data)\n",
    "\n",
    "# Replace the 'GET' or 'POST' Strings with NaN in the 'method' column in the DataFrame\n",
    "df_data['method'].replace(r'^((?!GET|POST).)*$', pd.np.nan, regex=True, inplace=True)\n",
    "\n",
    "# Dropping the rows with null values\n",
    "df_data.dropna(inplace=True)\n",
    "\n",
    "# Printing the deleted rows count\n",
    "print('there was', int_aux - len(df_data), 'non POST or GET records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Renaiming the columns\n",
    "df_data.columns = ['remote_addr', 'status', 'http_user_agent', 'time_local', 'request_method', 'request_url', 'request_protocol']\n",
    "#df_aux.columns = ['remote_addr', 'status', 'http_user_agent', 'time_local', 'request_method', 'request_url', 'request_protocol']\n",
    "\n",
    "# Dropping the 'remote_addr', 'time_local', 'request_protocol' columns\n",
    "df_data.drop(['remote_addr', 'time_local', 'request_protocol'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replacing the '-' character with '<NO_DATA>' in the 'http_user_agent' column to be more legible\n",
    "df_data['http_user_agent'].replace('-', '<NO_DATA>', inplace=True)\n",
    "\n",
    "# Reordering the columns\n",
    "df_data = df_data[['http_user_agent', 'request_method', 'status', 'request_url']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resetting the DataFrame indexes\n",
    "df_data = df_data.reset_index(drop=True)\n",
    "\n",
    "# Creating a new row for the human log evaluating\n",
    "df_data['is_evil'] = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "there are 6757 'php' urls, 4 'busybox' urls, 1457 'xml' urls and 51 'robots.txt' urls\n",
      "total evilized records are 6866 from 7717\n",
      "leaving 851 records to edit\n"
     ]
    }
   ],
   "source": [
    "# Filling some 'is_evil' values based on common words present on attacks to OUR server\n",
    "\n",
    "# Declaring search counters\n",
    "cont = 0\n",
    "cont2 = 0\n",
    "cont3 = 0\n",
    "cont4 = 0\n",
    "# Declaring total counter\n",
    "cont_t = 0\n",
    "# Declaring search Strings\n",
    "q_str = 'php'\n",
    "q_str2 = 'busybox'\n",
    "q_str3 = 'xml'\n",
    "q_str4 = 'robots.txt'\n",
    "\n",
    "# Iterating the DataFrame\n",
    "for i in df_data.itertuples():\n",
    "    is_counted = False\n",
    "    if q_str in i[4]:\n",
    "        cont += 1\n",
    "        df_data.at[i[0], 'is_evil'] = '1'\n",
    "        if not is_counted:\n",
    "            cont_t += 1\n",
    "            is_counted = True\n",
    "    if q_str2 in i[4]:\n",
    "        cont2 += 1\n",
    "        df_data.at[i[0], 'is_evil'] = '1'\n",
    "        if not is_counted:\n",
    "            cont_t += 1\n",
    "            is_counted = True\n",
    "    if q_str3 in i[4]:\n",
    "        cont3 += 1\n",
    "        df_data.at[i[0], 'is_evil'] = '1'\n",
    "        if not is_counted:\n",
    "            cont_t += 1\n",
    "            is_counted = True\n",
    "    if q_str4 in i[4]:\n",
    "        cont4 += 1\n",
    "        df_data.at[i[0], 'is_evil'] = '1'\n",
    "        if not is_counted:\n",
    "            cont_t += 1\n",
    "            is_counted = True\n",
    "\n",
    "# Printing the results\n",
    "print('there are', cont, '\\'' + q_str + '\\'', 'urls,', cont2, '\\'' + q_str2 + '\\'', 'urls,', cont3, '\\'' + q_str3 + '\\'', 'urls and', cont4, '\\'' + q_str4 + '\\'', 'urls')\n",
    "print('total evilized records are', cont_t, 'from', len(df_data))\n",
    "print('leaving', len(df_data) - cont_t, 'records to edit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total rows: 7717\n"
     ]
    }
   ],
   "source": [
    "# Sorting by 'is_evil' column\n",
    "df_data.sort_values('is_evil', inplace=True)\n",
    "\n",
    "# Exporting the DataFrame to an Excel file\n",
    "df_data.to_excel('data/log_data.xlsx')\n",
    "\n",
    "# Printing the number of rows\n",
    "print('total rows:',len(df_data))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
